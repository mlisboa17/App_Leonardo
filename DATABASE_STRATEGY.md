# ðŸ“Š EstratÃ©gia de Banco de Dados

## Status Atual - v1.0 (JSON)

### âœ… Implementado
- **JSON Files** para persistÃªncia de dados (GRÃTIS!)
- Audit logs em JSONL (append-only)
- MÃ©tricas em JSON
- ConfiguraÃ§Ãµes em YAML
- UsuÃ¡rios em JSON

### ðŸ“‚ Estrutura de Dados Atual
```
data/
â”œâ”€â”€ app_leonardo.db              # SQLite (vazio, reservado)
â”œâ”€â”€ users.json                   # UsuÃ¡rios e senhas (hashed)
â”œâ”€â”€ all_trades_history.json      # HistÃ³rico de trades
â”œâ”€â”€ multibot_positions.json      # PosiÃ§Ãµes atuais
â”œâ”€â”€ daily_stats.json             # EstatÃ­sticas diÃ¡rias
â”œâ”€â”€ control_log.json             # Log de aÃ§Ãµes
â”œâ”€â”€ audit/
â”‚   â””â”€â”€ audit_*.jsonl            # Eventos em JSONL (v1.1)
â”œâ”€â”€ ai/
â”‚   â””â”€â”€ ai_state.json            # Estado da IA
â””â”€â”€ backups/                     # Backups automÃ¡ticos
```

### âš¡ Vantagens JSON (Atual - GRÃTIS!)
- âœ… **ZERO CUSTO** - Sem servidor externo
- âœ… Sem dependÃªncias de BD externo
- âœ… FÃ¡cil de versionar (Git)
- âœ… Simples de fazer backup (tar/zip)
- âœ… Funciona offline
- âœ… Zero overhead de infra
- âœ… Funciona perfeitamente em AWS EC2 t3.micro

### âš ï¸ LimitaÃ§Ãµes JSON
- âŒ NÃ£o Ã© escalÃ¡vel (>1GB de dados)
- âŒ Sem queries SQL
- âŒ Sem Ã­ndices
- âŒ ConcorrÃªncia limitada
- âŒ Sem ACID completo
- âŒ Leitura lenta em grandes datasets

---

## ðŸ†“ OpÃ§Ãµes GRATUITAS para v2.0

### OpÃ§Ã£o 1: SQLite (MAIS FÃCIL - GRÃTIS!)

**O que Ã©:**
- Banco de dados leve embutido
- JÃ¡ vem com Python
- Arquivo Ãºnico (app_leonardo.db)
- Funciona em qualquer lugar

**Vantagens:**
- âœ… ZERO CUSTO
- âœ… Zero dependÃªncias externas
- âœ… FÃ¡cil migraÃ§Ã£o de JSON
- âœ… Funciona na AWS EC2
- âœ… Perfeito para aplicaÃ§Ãµes mÃ©dias
- âœ… Backup simples (copiar arquivo)

**LimitaÃ§Ãµes:**
- âŒ ConcorrÃªncia limitada (OK para bot Ãºnico)
- âŒ NÃ£o Ã© ideal para milhÃµes de registros

**Setup:**
```python
# Simplesmente criar conexÃ£o
import sqlite3

db = sqlite3.connect('data/app_leonardo.db')
cursor = db.cursor()

# Criar tabelas
cursor.execute('''
    CREATE TABLE trades (
        id INTEGER PRIMARY KEY,
        symbol TEXT,
        entry_price REAL,
        exit_price REAL,
        pnl REAL,
        entry_time TEXT,
        exit_time TEXT
    )
''')
db.commit()
```

**Custo:** **$0/mÃªs** âœ…

---

### OpÃ§Ã£o 2: PostgreSQL com Render.com (GRÃTIS + SEM CARTÃƒO!)

**O que Ã©:**
- PostgreSQL gerenciado na nuvem
- Tier gratuito: 400 horas/mÃªs (suficiente!)
- Sem cartÃ£o de crÃ©dito
- Banco de dados na nuvem

**Vantagens:**
- âœ… ZERO CUSTO (plano grÃ¡tis)
- âœ… Sem cartÃ£o de crÃ©dito necessÃ¡rio
- âœ… PostgreSQL completo
- âœ… Backups automÃ¡ticos
- âœ… SSL/TLS incluÃ­do
- âœ… FÃ¡cil setup

**LimitaÃ§Ãµes:**
- âš ï¸ Free tier: 400 horas/mÃªs (OK para desenvolvimento)
- âš ï¸ 256MB RAM
- âš ï¸ NÃ£o Ã© ideal para produÃ§Ã£o 24/7

**Setup:**
```
1. Ir para render.com
2. Sign up (GitHub grÃ¡tis)
3. Create â†’ PostgreSQL
4. Plano: Free
5. Copiar connection string
6. Usar em requirements: psycopg2
```

**Custo:** **$0/mÃªs** âœ…

---

### OpÃ§Ã£o 3: MongoDB Atlas (GRÃTIS - BANCO NÃƒO-SQL)

**O que Ã©:**
- Banco NoSQL na nuvem
- 512MB de espaÃ§o gratuito
- Sem cartÃ£o de crÃ©dito

**Vantagens:**
- âœ… ZERO CUSTO
- âœ… 512MB espaÃ§o grÃ¡tis
- âœ… JSON nativo
- âœ… FÃ¡cil para dados nÃ£o-estruturados
- âœ… Backups automÃ¡ticos

**LimitaÃ§Ãµes:**
- âš ï¸ Requer internet
- âš ï¸ 512MB limite (vocÃª pode atingir)
- âš ï¸ Menos estruturado que SQL

**Setup:**
```
1. Ir para mongodb.com
2. Sign up grÃ¡tis
3. Create cluster (free)
4. Connect string
5. Usar pymongo
```

**Custo:** **$0/mÃªs** âœ…

---

### OpÃ§Ã£o 4: AWS RDS Free Tier (GRÃTIS - 12 MESES!)

**O que Ã©:**
- PostgreSQL gerenciado na AWS
- GrÃ¡tis por 12 meses
- db.t3.micro
- 20GB armazenamento

**Vantagens:**
- âœ… GRÃTIS os primeiros 12 meses
- âœ… PostgreSQL completo
- âœ… Mesmo datacenter que EC2 (rÃ¡pido)
- âœ… Backups automÃ¡ticos
- âœ… FÃ¡cil escalar depois

**LimitaÃ§Ãµes:**
- âš ï¸ Free tier expira em 12 meses
- âš ï¸ ~$10-15/mÃªs depois do free tier
- âš ï¸ Precisa de cartÃ£o de crÃ©dito

**Setup:**
```bash
# AWS Console â†’ RDS â†’ Create Database
# PostgreSQL 15
# db.t3.micro (free tier)
# 20GB (free tier)

# Conectar da EC2
psql -h seu-rds-endpoint.com \
     -U admin \
     -d app_leonardo
```

**Custo:** **$0/mÃªs (primeiros 12 meses)** â†’ ~$15/mÃªs depois

---

## ðŸŽ¯ RECOMENDAÃ‡ÃƒO: Qual Usar?

### Para AGORA (v1.0):
```
âœ… MANTER JSON + SQLite
- Zero custo
- Zero dependÃªncias
- Funciona perfeitamente
- FÃ¡cil backup
- Sem complicaÃ§Ãµes
```

### Para v1.5 (Quando quiser BD):
```
âœ… USAR SQLite
- Upgrade mÃ­nimo
- GrÃ¡tis
- Sem servidor externo
- Mesmo arquivo para backup
- Ideal transiÃ§Ã£o JSON â†’ Banco de dados
```

### Para v2.0 (Quando escalar):
```
âœ… USAR Render.com (PostgreSQL grÃ¡tis)
ou
âœ… USAR AWS RDS Free Tier (12 meses grÃ¡tis)
```

---

## ðŸ’¡ EstratÃ©gia de MigraÃ§Ã£o (SEM CUSTO)

```
HOJE (v1.0):
â”œâ”€ JSON Files (GRÃTIS)
â”‚  â”œâ”€ users.json
â”‚  â”œâ”€ trades.json
â”‚  â”œâ”€ positions.json
â”‚  â””â”€ daily_stats.json
â”‚
MÃŠS 1-2 (v1.5):
â”œâ”€ Adicionar SQLite (GRÃTIS)
â”‚  â””â”€ app_leonardo.db (arquivo local)
â”‚  â””â”€ Scripts para migrar JSON â†’ SQLite
â”‚
MÃŠS 3-6 (v2.0):
â”œâ”€ Adicionar PostgreSQL (GRÃTIS)
â”‚  â””â”€ Render.com OR AWS RDS Free Tier
â”‚  â””â”€ Scripts para migrar SQLite â†’ PostgreSQL
â”‚
DEPOIS (Quando escalar):
â””â”€ Pagar apenas se atingir limites
   (~$15/mÃªs PostgreSQL ou manter grÃ¡tis)
```

---

## ðŸ“Š ComparaÃ§Ã£o de Custo

| BD | Setup | v1.0 | v2.0 | 12m+ |
|----|----|------|------|------|
| **JSON** | 0 min | **$0** | NÃ£o | NÃ£o |
| **SQLite** | 5 min | **$0** | **$0** | **$0** |
| **Render.com** | 10 min | N/A | **$0** | **$7-10/mÃªs** |
| **AWS RDS** | 15 min | N/A | **$0** | **$15+/mÃªs** |
| **MongoDB Atlas** | 10 min | N/A | **$0** | **$15+/mÃªs** |

âœ… **ESCOLHA**: Manter JSON + SQLite = SEMPRE GRÃTIS!

---

## ðŸ”„ MigraÃ§Ã£o JSON â†’ SQLite (Quando quiser)

```python
# Script simples de migraÃ§Ã£o
import json
import sqlite3

# Ler JSON
with open('data/all_trades_history.json') as f:
    trades = json.load(f)

# Criar SQLite
db = sqlite3.connect('data/app_leonardo.db')
cursor = db.cursor()

# Inserir dados
for trade in trades:
    cursor.execute('''
        INSERT INTO trades 
        (symbol, entry_price, exit_price, pnl)
        VALUES (?, ?, ?, ?)
    ''', (trade['symbol'], trade['entry'], 
          trade['exit'], trade['pnl']))

db.commit()
db.close()

print(f"âœ… Migrados {len(trades)} trades para SQLite")
```

---

## âœ… CONCLUSÃƒO

### Para AGORA (v1.0):
**âœ… USE JSON - Ã‰ GRÃTIS E FUNCIONA PERFEITAMENTE!**

```
Custo: $0/mÃªs
Banco: JSON Files (jÃ¡ funciona)
Quando escalar: Migrar para SQLite
Depois: OpÃ§Ãµes gratuitas (Render, AWS RDS Free)
```

### Seu Stack Gratuito:
```
Frontend:     React (grÃ¡tis)
Backend:      FastAPI (grÃ¡tis)
Database:     JSON (grÃ¡tis) â†’ SQLite (grÃ¡tis)
Servidor:     AWS EC2 t3.micro ($0/12m, depois $5-8/mÃªs)
Armazenamento: S3 Backup (~$0.03/mÃªs)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:        $1-5/mÃªs por 12 meses!
```

NÃ£o precisa gastar NADA com banco de dados! ðŸŽ‰

---

## ðŸš€ PrÃ³ximos Passos

### Agora:
- âœ… Deploy em AWS com JSON (jÃ¡ pronto)
- âœ… Usar arquivos JSON que jÃ¡ tem

### v1.5 (Quando quiser melhorar):
- â³ Adicionar SQLite (100% grÃ¡tis)
- â³ Migrar dados quando atingir ~100MB

### v2.0+ (Quando escalar muito):
- â³ PostgreSQL Render.com OU AWS RDS
- â³ Ambos com opÃ§Ãµes gratuitas!

**Bottom line**: Seu bot pode rodar SEM CUSTO por TEMPO ILIMITADO! ðŸŽ¯

### ðŸ“‹ Plano de MigraÃ§Ã£o (v2.0)

#### Fase 1: Preparar BD
```sql
-- Criar database
CREATE DATABASE app_leonardo;

-- Criar schemas
CREATE SCHEMA trading;
CREATE SCHEMA audit;
CREATE SCHEMA metrics;

-- Tabelas principais
CREATE TABLE trading.users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255),
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    last_login TIMESTAMP
);

CREATE TABLE trading.bots (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    bot_type VARCHAR(50),
    enabled BOOLEAN DEFAULT FALSE,
    config JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE trading.positions (
    id SERIAL PRIMARY KEY,
    bot_id INTEGER REFERENCES trading.bots(id),
    symbol VARCHAR(20) NOT NULL,
    side VARCHAR(10),
    entry_price DECIMAL(20,8),
    quantity DECIMAL(20,8),
    entry_time TIMESTAMP,
    current_price DECIMAL(20,8),
    pnl DECIMAL(20,8),
    status VARCHAR(20),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE trading.trades (
    id SERIAL PRIMARY KEY,
    bot_id INTEGER REFERENCES trading.bots(id),
    symbol VARCHAR(20) NOT NULL,
    entry_price DECIMAL(20,8),
    exit_price DECIMAL(20,8),
    quantity DECIMAL(20,8),
    pnl DECIMAL(20,8),
    pnl_percent DECIMAL(10,4),
    entry_time TIMESTAMP,
    exit_time TIMESTAMP,
    status VARCHAR(20),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabelas de Audit
CREATE TABLE audit.events (
    id SERIAL PRIMARY KEY,
    event_type VARCHAR(50) NOT NULL,
    severity VARCHAR(20),
    source VARCHAR(100),
    target VARCHAR(100),
    action VARCHAR(255),
    details JSONB,
    timestamp TIMESTAMP DEFAULT NOW(),
    user_id INTEGER REFERENCES trading.users(id)
);

-- Tabelas de MÃ©tricas
CREATE TABLE metrics.performance (
    id SERIAL PRIMARY KEY,
    bot_id INTEGER REFERENCES trading.bots(id),
    metric_name VARCHAR(100),
    metric_value FLOAT,
    timestamp TIMESTAMP DEFAULT NOW()
);

-- Ãndices
CREATE INDEX idx_positions_bot_id ON trading.positions(bot_id);
CREATE INDEX idx_positions_symbol ON trading.positions(symbol);
CREATE INDEX idx_trades_bot_id ON trading.trades(bot_id);
CREATE INDEX idx_trades_entry_time ON trading.trades(entry_time);
CREATE INDEX idx_audit_timestamp ON audit.events(timestamp);
CREATE INDEX idx_audit_event_type ON audit.events(event_type);
```

#### Fase 2: Setup da API
```python
# requirements_db.txt (novo)
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.13.0
python-dotenv==1.0.0

# backend/database.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base

DATABASE_URL = "postgresql://user:password@localhost:5432/app_leonardo"
engine = create_engine(DATABASE_URL, echo=False)
SessionLocal = sessionmaker(bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# backend/models.py
from sqlalchemy import Column, Integer, String, Float, JSONB, Timestamp, Boolean
from datetime import datetime
from .database import Base

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True)
    username = Column(String, unique=True, index=True)
    email = Column(String)
    password_hash = Column(String)
    created_at = Column(Timestamp, default=datetime.utcnow)

class Bot(Base):
    __tablename__ = "bots"
    id = Column(Integer, primary_key=True)
    name = Column(String, index=True)
    bot_type = Column(String)
    enabled = Column(Boolean, default=False)
    config = Column(JSONB)
    created_at = Column(Timestamp, default=datetime.utcnow)

class Trade(Base):
    __tablename__ = "trades"
    id = Column(Integer, primary_key=True)
    bot_id = Column(Integer)
    symbol = Column(String, index=True)
    entry_price = Column(Float)
    exit_price = Column(Float)
    pnl = Column(Float)
    entry_time = Column(Timestamp, index=True)
    exit_time = Column(Timestamp)
```

#### Fase 3: Migrar Dados
```bash
# Script para migrar JSON â†’ PostgreSQL
python migrate_json_to_postgres.py

# Verificar integridade
python validate_migration.py

# Backup do JSON (manter como backup)
tar -czf data_backup_json.tar.gz data/
```

#### Fase 4: Implementar Queries Otimizadas
```python
# Exemplo: listar trades do mÃªs
@app.get("/api/trades/monthly")
async def get_monthly_trades(db: Session = Depends(get_db)):
    trades = db.query(Trade).filter(
        Trade.exit_time >= datetime(2025, 1, 1),
        Trade.exit_time < datetime(2025, 2, 1)
    ).order_by(Trade.exit_time.desc()).all()
    return trades

# Exemplo: listar posiÃ§Ãµes ativas
@app.get("/api/positions/active")
async def get_active_positions(db: Session = Depends(get_db)):
    positions = db.query(Position).filter(
        Position.status == 'open'
    ).all()
    return positions
```

---

## â˜ï¸ AWS RDS - Setup para v2.0

### OpÃ§Ã£o 1: RDS PostgreSQL (Recomendado)
```bash
# AWS Console
# RDS â†’ Create Database â†’ PostgreSQL 15

# ConfiguraÃ§Ã£o
- Engine: PostgreSQL 15.x
- DB instance class: db.t3.micro (Free tier)
- Storage: 20GB gp3
- Multi-AZ: No (para economizar)
- Backup retention: 7 days
- Encryption: Enabled

# Custo mensal
- Compute: ~$10-15/mÃªs
- Storage: ~$2-3/mÃªs
- Data transfer: GrÃ¡tis (VPC)
- TOTAL: ~$12-18/mÃªs
```

### OpÃ§Ã£o 2: Aurora PostgreSQL (Mais caro, mas melhor)
```
Custo: ~$50-100/mÃªs
Vantagens: Auto-scaling, read replicas, mais uptime
```

### ConexÃ£o da EC2 ao RDS
```bash
# .env na EC2
DATABASE_URL=postgresql://admin:senha_segura@app-leonardo-db.xxxxx.us-east-1.rds.amazonaws.com:5432/app_leonardo

# Testar conexÃ£o
psql -h app-leonardo-db.xxxxx.us-east-1.rds.amazonaws.com \
     -U admin \
     -d app_leonardo
```

---

## ðŸ”’ Backup e RecuperaÃ§Ã£o

### Backup JSON (Atual)
```bash
# DiÃ¡rio
0 2 * * * tar -czf ~/backups/data_$(date +\%Y\%m\%d).tar.gz ~/app-leonardo/data/
aws s3 sync ~/backups s3://app-leonardo-backups/
```

### Backup PostgreSQL (v2.0)
```bash
# RDS faz backup automÃ¡tico
# Manual backup (via AWS CLI)
aws rds create-db-snapshot \
  --db-instance-identifier app-leonardo-db \
  --db-snapshot-identifier app-leonardo-snapshot-$(date +%Y%m%d)
```

---

## ðŸ“Š Monitoramento

### MÃ©tricas Atuais (JSON)
- Tamanho dos arquivos
- NÃºmero de trades
- PosiÃ§Ãµes ativas
- Uptime do bot

### MÃ©tricas Futuras (PostgreSQL + Prometheus)
```python
# Coletar mÃ©tricas do PostgreSQL
query_count = "SELECT COUNT(*) FROM trades"
table_size = "SELECT pg_size_pretty(pg_total_relation_size('trades'))"
active_queries = "SELECT COUNT(*) FROM pg_stat_activity WHERE state = 'active'"

# Expor em Prometheus
@app.get("/metrics")
async def metrics():
    return f"""
# HELP trades_total Total de trades
# TYPE trades_total counter
trades_total {trade_count}

# HELP db_size_bytes Tamanho da database
# TYPE db_size_bytes gauge
db_size_bytes {db_size_bytes}

# HELP active_connections ConexÃµes ativas
# TYPE active_connections gauge
active_connections {active_conns}
"""
```

---

## ðŸŽ¯ Timeline

| Fase | Tarefa | v1.0 | v1.1 | v2.0 |
|------|--------|------|------|------|
| Setup | Prod deploy | âœ… | âœ… | - |
| DB | JSON | âœ… | âœ… | - |
| Audit | JSONL logs | - | âœ… | Migrar â†’ PostgreSQL |
| Observability | MÃ©tricas | - | âœ… | + Prometheus/Grafana |
| Backup | S3 automÃ¡tico | - | - | âœ… |
| Security | Rate limiting | - | - | âœ… |
| Replication | Read replicas | - | - | âœ… (Aurora) |

---

## ðŸ“ž Suporte

**v1.0 - Atual (JSON)**
- Consultar arquivos em `data/`
- Backups automÃ¡ticos
- Sem queries SQL

**v2.0 - Planejado (PostgreSQL)**
- Queries SQL completas
- Ãndices automÃ¡ticos
- Dashboards com Grafana
- Alertas baseados em thresholds

---

**PrÃ³ximo passo**: Deploy atual em AWS (v1.0 com JSON)  
**Quando migrar**: Quando atingir 1GB de dados ou precisar de queries complexas  
**Sem urgÃªncia**: Sistema funciona bem com JSON por enquanto
